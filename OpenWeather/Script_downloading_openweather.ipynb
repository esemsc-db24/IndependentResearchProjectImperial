{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj5YaZaJ-b1h",
        "outputId": "89cdf83b-0020-4958-f08d-52f0a3a80d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG7ll8s2AcuU",
        "outputId": "44e5073d-8c67-4a09-b474-2188d898d3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned data: 47374 rows to process\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "API_KEY = 'this_is_where_the_api_key_was'\n",
        "BASE_URL = 'http://api.openweathermap.org/data/2.5/air_pollution/history'\n",
        "TIME_LAPSE = 3600  # 1-hour window in seconds\n",
        "\n",
        "# === FILE PATHS ===\n",
        "file_path = \"/content/drive/MyDrive/requests/request135_139.csv\"\n",
        "output_dir = \"/content/drive/MyDrive/results/\"\n",
        "output_file = os.path.join(output_dir, \"pollution_results_incremental135_139.csv\")\n",
        "\n",
        "# === LOAD AND CLEAN INPUT ===\n",
        "data = pd.read_csv(file_path, na_values=['', ' ', 'N/A'])\n",
        "data = data.dropna(subset=['timestamp_hour', 'latitude', 'longitude'])\n",
        "data['timestamp_hour'] = pd.to_datetime(data['timestamp_hour'], utc=True)\n",
        "\n",
        "# Round lat/lon for precision-safe matching\n",
        "data['lat_round'] = data['latitude'].round(5)\n",
        "data['lon_round'] = data['longitude'].round(5)\n",
        "\n",
        "# === PREPARE OUTPUT DIRECTORY AND FILE ===\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "if os.path.exists(output_file):\n",
        "    existing = pd.read_csv(output_file)\n",
        "    existing['lat_round'] = existing['latitude'].round(5)\n",
        "    existing['lon_round'] = existing['longitude'].round(5)\n",
        "    processed_keys = set(zip(existing['lat_round'], existing['lon_round'], existing['start_time']))\n",
        "else:\n",
        "    header_cols = ['latitude', 'longitude', 'start_time', 'end_time', 'AQI',\n",
        "                   'pm2_5', 'pm10', 'no', 'no2', 'o3', 'so2', 'co']\n",
        "    pd.DataFrame(columns=header_cols).to_csv(output_file, index=False)\n",
        "    processed_keys = set()\n",
        "\n",
        "print(f\"Cleaned data: {len(data)} rows to process\")\n",
        "start_script_time = time.time()\n",
        "\n",
        "# === LOOP THROUGH EACH ROW ===\n",
        "for i, row in data.iterrows():\n",
        "    lat = row['latitude']\n",
        "    lon = row['longitude']\n",
        "    ts = row['timestamp_hour']\n",
        "    lat_r = row['lat_round']\n",
        "    lon_r = row['lon_round']\n",
        "\n",
        "    try:\n",
        "        start_time = int(ts.timestamp())\n",
        "        end_time = start_time + TIME_LAPSE\n",
        "    except Exception as e:\n",
        "        print(f\"Timestamp error at row {i}: {ts} - {e}\")\n",
        "        continue\n",
        "\n",
        "    key = (lat_r, lon_r, start_time)\n",
        "    if key in processed_keys:\n",
        "        continue  # Skip already processed row\n",
        "\n",
        "    # === API Request ===\n",
        "    url = f\"{BASE_URL}?lat={lat}&lon={lon}&start={start_time}&end={end_time}&appid={API_KEY}\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            pollution_data = response.json()\n",
        "            if 'list' in pollution_data and len(pollution_data['list']) > 0:\n",
        "                data_point = pollution_data['list'][0]\n",
        "                aqi = data_point['main']['aqi']\n",
        "                comp = data_point['components']\n",
        "            else:\n",
        "                aqi = 'N/A'\n",
        "                comp = {}\n",
        "        else:\n",
        "            print(f\"API status {response.status_code} at row {i}\")\n",
        "            aqi = 'Error'\n",
        "            comp = {}\n",
        "    except Exception as e:\n",
        "        print(f\"API error at row {i}: {e}\")\n",
        "        aqi = 'Error'\n",
        "        comp = {}\n",
        "\n",
        "    # === Append Result ===\n",
        "    result = {\n",
        "        'latitude': lat,\n",
        "        'longitude': lon,\n",
        "        'start_time': start_time,\n",
        "        'end_time': end_time,\n",
        "        'AQI': aqi,\n",
        "        'pm2_5': comp.get('pm2_5'),\n",
        "        'pm10': comp.get('pm10'),\n",
        "        'no': comp.get('no'),\n",
        "        'no2': comp.get('no2'),\n",
        "        'o3': comp.get('o3'),\n",
        "        'so2': comp.get('so2'),\n",
        "        'co': comp.get('co')\n",
        "    }\n",
        "\n",
        "    pd.DataFrame([result]).to_csv(output_file, mode='a', header=False, index=False)\n",
        "\n",
        "    time.sleep(0.0000000001)  # respect rate limits\n",
        "\n",
        "# === TOTAL TIME ===\n",
        "total_time = time.time() - start_script_time\n",
        "mins, secs = divmod(total_time, 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
